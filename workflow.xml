<tool id='alvaro_singlecluster_parsl_demo' name='alvaro_singlecluster_parsl_demo'>
  <command interpreter='bash'>parsl_wrapper.sh</command>
  <inputs>
    <section name='train' type='section' title='Training host' expanded='true'>
      <param name='_pw_train_resource_name' label='Resource name' type='text' value='awsv2' help='Name of the PW resource to train the model' width='50%_none'></param>
      <param name='_pw_train_load_pytorch' label='Load pytorch command' type='text' value='source___/contrib/miniconda/etc/profile.d/conda.sh;___conda___activate___pytorch-gpu' help='Command to load pytorch on this resource' width='50%_none'></param>
      <param name='_pw_train_max_runtime' label='Walltime [s]' type='text' value='600' help='Maximum runtime in seconds including queue time' width='50%_none'></param>
      <param name='_pw_train_workdir' label='Walltime [s]' type='text' value='/home/__USER__' help='Maximum runtime in seconds including queue time' width='50%_none'></param>
      <conditional name="jobschedulertype_cond">
          <param name='_pw_jobschedulertype' type='select' label='Select Controller, SLURM Partition or PBS Queue' help='Job will submitted using SSH, sbatch or qsub, respectively' width='50%_none' multiple='false'>
            <option value="SLURM" selected="true">SLURM Partition </option>
            <option value="PBS">PBS Queue</option>
            <option value="CONTROLLER" selected="true">Controller</option>
        </param>
        <when value="SLURM">
            <param name='_pw__sch__dd_partition_e_' label='SLURM partition' type='text' help='Partition to submit the interactive job. Leave empty to let SLURM pick the optimal option.' value='gpu-us-east-1a' width='50%_none'>
            </param>
            <param name='_pw_scheduler_directives' label='Scheduler directives' type='text' help='e.g. --mem=1000;--gpus-per-node=1 - Use the semicolon character ; to separate parameters. Do not include the SBATCH keyword.' value='--nodes=1;--exclusive;--time=01:00:00' width='100%_none'>
            </param>
        </when>
        <when value="PBS">
            <param name='_pw__sch__d_q___' label='PBS queue' type='text' help='Queue to submit the interactive job. Must select one! Use [qstat -f -Q] to list all queues on the system' value='debug' width='50%_none'>
            </param>
            <param name='_pw_scheduler_directives' label='Scheduler directives' type='text' help='e.g. -l mem=1000;-l nodes=1:ppn=4 - Use the semicolon character ; to separate parameters. Do not include the PBS keyword.' value='-A___HPCMO49636PRW;-l___select=1:ncpus=44:mpiprocs=44;-l___walltime=00:10:00;-V' width='100%_none'>
            </param>
        </when>
      </conditional>
    </section>
    <section name='train_params' type='section' title='Train' expanded='true'>
      <param 
        name='latent_size' 
        label='Latent Size' 
        type='integer' 
        min='1' 
        max='10' 
        help='Latent dimension of the encoded space' 
        value='2' 
        width='50%'>
      </param>
      <param 
        name='num_epochs' 
        label='Number of Epochs' 
        type='integer' 
        min='1' 
        max='1000' 
        value='10'
        width='50%'>
      </param>
      <param 
        name='learning_rate' 
        label='Learning Rate' 
        type='text' 
        value='0.001' 
        width='50%'>
      </param>
    </section>
    <section name='inference_params' type='section' title='Inference' expanded='true'>
      <param 
        name='num_digits' 
        label='Number of Digits' 
        type='integer' 
        min='2' 
        max='1000' 
        help='Number of digits to generate' 
        value='10' 
        width='50%'>
      </param>
    </section>
  </inputs>
  <outputs>
  </outputs>
</tool>
